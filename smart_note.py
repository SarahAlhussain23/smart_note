# smart_note.py


import streamlit as st
import requests
import json
from datetime import datetime
import os
from typing import Optional, Dict, Any

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©

st.set_page_config(
page_title=â€œØ§Ù„Ù†ÙˆØª Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…Ø­Ø³Ù†â€,
page_icon=â€œğŸ“â€,
layout=â€œwideâ€,
initial_sidebar_state=â€œexpandedâ€
)

# Ø¥Ø¶Ø§ÙØ© CSS Ù…Ø®ØµØµ Ù„Ù„ØªØµÙ…ÙŠÙ…

st.markdown(â€â€â€

<style>
    .main-header {
        text-align: center;
        color: #2E86C1;
        font-size: 2.5em;
        margin-bottom: 0.5em;
    }
    .feature-box {
        background-color: #F8F9FA;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #2E86C1;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #D5EDDA;
        padding: 1rem;
        border-radius: 10px;
        border-left: 4px solid #28A745;
    }
    .rtl {
        direction: rtl;
        text-align: right;
    }
</style>

â€œâ€â€, unsafe_allow_html=True)

# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª

st.sidebar.title(â€œâš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øªâ€)

# Ø§Ø®ØªÙŠØ§Ø± Ù…Ù‚Ø¯Ù… Ø§Ù„Ø®Ø¯Ù…Ø©

provider = st.sidebar.selectbox(
â€œØ§Ø®ØªØ± Ù…Ù‚Ø¯Ù… Ø®Ø¯Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:â€,
[â€œOpenAIâ€, â€œOllama (Ù…Ø­Ù„ÙŠ)â€, â€œHugging Faceâ€]
)

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø®ØªÙ„ÙØ© Ø­Ø³Ø¨ Ø§Ù„Ù…Ù‚Ø¯Ù…

if provider == â€œOpenAIâ€:
api_key = st.sidebar.text_input(â€œÙ…ÙØªØ§Ø­ OpenAI API:â€, type=â€œpasswordâ€)
model = st.sidebar.selectbox(â€œØ§Ù„Ù†Ù…ÙˆØ°Ø¬:â€, [â€œgpt-4â€, â€œgpt-3.5-turboâ€])
elif provider == â€œOllama (Ù…Ø­Ù„ÙŠ)â€:
ollama_url = st.sidebar.text_input(â€œØ±Ø§Ø¨Ø· Ollama:â€, value=â€œhttp://localhost:11434â€)
model = st.sidebar.text_input(â€œØ§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:â€, value=â€œllama2â€)
elif provider == â€œHugging Faceâ€:
hf_token = st.sidebar.text_input(â€œHugging Face Token:â€, type=â€œpasswordâ€)
model = st.sidebar.selectbox(â€œØ§Ù„Ù†Ù…ÙˆØ°Ø¬:â€, [â€œmicrosoft/DialoGPT-mediumâ€, â€œfacebook/blenderbot-400M-distillâ€])

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ®ØµÙŠØµ

st.sidebar.subheader(â€œğŸ¨ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØ®ØµÙŠØµâ€)
organization_style = st.sidebar.selectbox(
â€œÙ†Ù…Ø· Ø§Ù„ØªÙ†Ø¸ÙŠÙ…:â€,
[â€œÙ†Ù‚Ø§Ø· Ø±Ø¦ÙŠØ³ÙŠØ©â€, â€œÙ‚ÙˆØ§Ø¦Ù… Ù…Ø±Ù‚Ù…Ø©â€, â€œÙÙ‚Ø±Ø§Øª Ù…Ù†Ø¸Ù…Ø©â€, â€œØ¬Ø¯ÙˆÙ„â€, â€œØ®Ø±ÙŠØ·Ø© Ø°Ù‡Ù†ÙŠØ©â€]
)

temperature = st.sidebar.slider(â€œÙ…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹:â€, 0.1, 1.0, 0.7)
max_tokens = st.sidebar.slider(â€œØ§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰:â€, 100, 2000, 500)

# Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ

st.markdown(â€™<h1 class="main-header">ğŸ“ Ø§Ù„Ù†ÙˆØª Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…Ø­Ø³Ù†</h1>â€™, unsafe_allow_html=True)
st.markdown(â€™<div class="rtl">Ø£Ø¯Ø®Ù„ Ù…Ù„Ø§Ø­Ø¸Ø§ØªÙƒ Ø£Ùˆ Ø£ÙÙƒØ§Ø±ÙƒØŒ ÙˆØ³Ø£Ø±ØªØ¨Ù‡Ø§ ÙˆØ£Ø­Ø³Ù†Ù‡Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ!</div>â€™, unsafe_allow_html=True)

# ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø©

def save_to_session_state(key: str, value: Any):
â€œâ€â€œØ­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©â€â€â€
if â€˜historyâ€™ not in st.session_state:
st.session_state.history = []
st.session_state[key] = value

def get_ai_response_openai(prompt: str, api_key: str, model: str) -> Optional[str]:
â€œâ€â€œØ§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI APIâ€â€â€
try:
import openai
openai.api_key = api_key
    response = openai.ChatCompletion.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
        temperature=temperature,
        max_tokens=max_tokens
    )
    
    return response.choices[0].message.content
except Exception as e:
    st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ OpenAI: {str(e)}")
    return None

def get_ai_response_ollama(prompt: str, url: str, model: str) -> Optional[str]:
â€œâ€â€œØ§Ø³ØªØ¯Ø¹Ø§Ø¡ Ollama APIâ€â€â€
try:
response = requests.post(
fâ€{url}/api/generateâ€,
json={
â€œmodelâ€: model,
â€œpromptâ€: prompt,
â€œstreamâ€: False,
â€œoptionsâ€: {
â€œtemperatureâ€: temperature,
â€œnum_predictâ€: max_tokens
}
},
timeout=30
)
    if response.status_code == 200:
        return response.json().get("response", "")
    else:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {response.status_code}")
        return None
except Exception as e:
    st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ø¹ Ollama: {str(e)}")
    return None

def get_ai_response_huggingface(prompt: str, token: str, model: str) -> Optional[str]:
â€œâ€â€œØ§Ø³ØªØ¯Ø¹Ø§Ø¡ Hugging Face APIâ€â€â€
try:
headers = {â€œAuthorizationâ€: fâ€Bearer {token}â€}
data = {â€œinputsâ€: prompt, â€œparametersâ€: {â€œmax_lengthâ€: max_tokens, â€œtemperatureâ€: temperature}}
    response = requests.post(
        f"https://api-inference.huggingface.co/models/{model}",
        headers=headers,
        json=data,
        timeout=30
    )
    
    if response.status_code == 200:
        result = response.json()
        if isinstance(result, list) and len(result) > 0:

sara, [8/13/2025 12:33 AM]
return result[0].get("generated_text", "")
        return str(result)
    else:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©: {response.status_code}")
        return None
except Exception as e:
    st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ù…Ø¹ Hugging Face: {str(e)}")
    return None

def create_enhanced_prompt(user_input: str, style: str) -> str:
â€œâ€â€œØ¥Ù†Ø´Ø§Ø¡ prompt Ù…Ø­Ø³Ù†â€â€â€
style_instructions = {
â€œÙ†Ù‚Ø§Ø· Ø±Ø¦ÙŠØ³ÙŠØ©â€: â€œØ±ØªØ¨ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ Ø´ÙƒÙ„ Ù†Ù‚Ø§Ø· Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙˆÙ…Ø®ØªØµØ±Ø©â€,
â€œÙ‚ÙˆØ§Ø¦Ù… Ù…Ø±Ù‚Ù…Ø©â€: â€œØ±ØªØ¨ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ Ù‚Ø§Ø¦Ù…Ø© Ù…Ø±Ù‚Ù…Ø© Ù…Ù†Ø·Ù‚ÙŠØ©â€,
â€œÙÙ‚Ø±Ø§Øª Ù…Ù†Ø¸Ù…Ø©â€: â€œØ§ÙƒØªØ¨ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ ÙÙ‚Ø±Ø§Øª Ù…Ù†Ø¸Ù…Ø© ÙˆÙ…ØªØ±Ø§Ø¨Ø·Ø©â€,
â€œØ¬Ø¯ÙˆÙ„â€: â€œÙ†Ø¸Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ Ø´ÙƒÙ„ Ø¬Ø¯ÙˆÙ„ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø°Ù„Ùƒ Ù…Ù†Ø§Ø³Ø¨Ø§Ù‹â€,
â€œØ®Ø±ÙŠØ·Ø© Ø°Ù‡Ù†ÙŠØ©â€: â€œØ±ØªØ¨ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨Ø´ÙƒÙ„ Ù‡Ø±Ù…ÙŠ ÙƒØ®Ø±ÙŠØ·Ø© Ø°Ù‡Ù†ÙŠØ©â€
}
return f"""
Ø§Ù„Ù…Ù‡Ù…Ø©: ØªÙ†Ø¸ÙŠÙ… ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©

Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©:
{user_input}

Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª:
1. {style_instructions.get(style, "Ø±ØªØ¨ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¨Ø´ÙƒÙ„ ÙˆØ§Ø¶Ø­ ÙˆÙ…Ù†Ø·Ù‚ÙŠ")}
2. Ø£Ø¶Ù Ø¹Ù†Ø§ÙˆÙŠÙ† ÙØ±Ø¹ÙŠØ© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
3. ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¶ÙˆØ­ Ø§Ù„Ù†Øµ ÙˆØ³Ù‡ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡ØªÙ‡
4. Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„Ø£ØµÙ„ÙŠ
5. Ø£Ø¶Ù Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙÙŠØ¯Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø°Ù„Ùƒ Ù…Ù†Ø§Ø³Ø¨Ø§Ù‹

Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {style}

Ø§ÙƒØªØ¨ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:
"""

# Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

col1, col2 = st.columns([2, 1])

with col1:
# Ù…Ù†Ø·Ù‚Ø© Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª
st.subheader(â€œâœï¸ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øªâ€)
user_input = st.text_area(
â€œØ§ÙƒØªØ¨ Ù…Ù„Ø§Ø­Ø¸Ø§ØªÙƒ Ù‡Ù†Ø§:â€,
height=200,
placeholder=â€œÙ…Ø«Ø§Ù„: Ø§Ø¬ØªÙ…Ø§Ø¹ Ø§Ù„ÙŠÙˆÙ…ØŒ Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ØŒ Ø£ÙÙƒØ§Ø± Ø¬Ø¯ÙŠØ¯Ø©â€¦â€
)
# Ø®ÙŠØ§Ø±Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
col_btn1, col_btn2, col_btn3 = st.columns(3)

with col_btn1:
    process_btn = st.button("ğŸš€ ØªØ±ØªÙŠØ¨ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª", type="primary")

with col_btn2:
    clear_btn = st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù†Øµ")

with col_btn3:
    save_btn = st.button("ğŸ’¾ Ø­ÙØ¸ ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ®")

with col2:
# Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
st.subheader(â€œğŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Øµâ€)
if user_input:
word_count = len(user_input.split())
char_count = len(user_input)
st.metric(â€œØ¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øªâ€, word_count)
st.metric(â€œØ¹Ø¯Ø¯ Ø§Ù„Ø£Ø­Ø±Ùâ€, char_count)
# Ù†ØµØ§Ø¦Ø­ Ø³Ø±ÙŠØ¹Ø©
st.markdown("""
<div class="feature-box">
    <h4>ğŸ’¡ Ù†ØµØ§Ø¦Ø­ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ù…Ø«Ù„:</h4>
    <ul>
        <li>Ø§ÙƒØªØ¨ Ø£ÙÙƒØ§Ø±Ùƒ Ø¨Ø­Ø±ÙŠØ©</li>
        <li>Ù„Ø§ ØªÙ‚Ù„Ù‚ Ø¨Ø´Ø£Ù† Ø§Ù„ØªÙ†Ø¸ÙŠÙ…</li>
        <li>Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©</li>
        <li>Ø§Ø°ÙƒØ± Ø§Ù„Ø³ÙŠØ§Ù‚ Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±</li>
    </ul>
</div>
""", unsafe_allow_html=True)

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø²Ø±Ø§Ø±

if clear_btn:
st.rerun()

if process_btn:
if not user_input.strip():
st.warning(â€œâš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø£ÙˆÙ„Ø§Ù‹.â€)
else:
# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
config_valid = True
error_msg = â€œâ€
    if provider == "OpenAI" and not api_key:
        config_valid = False
        error_msg = "ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ù…ÙØªØ§Ø­ OpenAI API"
    elif provider == "Hugging Face" and not hf_token:
        config_valid = False
        error_msg = "ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Hugging Face Token"
    
    if config_valid:
        with st.spinner("ğŸ¤– Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ø§Ø­Ø¸Ø§ØªÙƒ..."):
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù€ prompt
            enhanced_prompt = create_enhanced_prompt(user_input, organization_style)
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù€ API Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
            output_text = None
            
            if provider == "OpenAI":
                output_text = get_ai_response_openai(enhanced_prompt, api_key, model)
            elif provider == "Ollama (Ù…Ø­Ù„ÙŠ)":
                output_text = get_ai_response_ollama(enhanced_prompt, ollama_url, model)
            elif provider == "Hugging Face":
                output_text = get_ai_response_huggingface(enhanced_prompt, hf_token, model)
            
            if output_text:
                # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                st.markdown("---")
                st.subheader("ğŸ“„ Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ù…Ø±ØªØ¨Ø©:")
                st.markdown(f'<div class="success-box rtl">{output_text}</div>', unsafe_allow_html=True)
                
                # Ø­ÙØ¸ ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ®
                if 'history' not in st.session_state:
                    st.session_state.history = []
                
                st.session_state.history.append({
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "original": user_input,
                    "processed": output_text,
                    "style": organization_style,
                    "provider": provider
                })
                
                # Ø£Ø²Ø±Ø§Ø± Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ù†ØªÙŠØ¬Ø©

sara, [8/13/2025 12:33 AM]
col_result1, col_result2, col_result3 = st.columns(3)
                
                with col_result1:
                    if st.button("ğŸ“‹ Ù†Ø³Ø® Ø§Ù„Ù†ØªÙŠØ¬Ø©"):
                        st.success("ØªÙ… Ù†Ø³Ø® Ø§Ù„Ù†Øµ!")
                
                with col_result2:
                    # Ø²Ø± Ø§Ù„ØªØ­Ù…ÙŠÙ„
                    st.download_button(
                        "ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø©",
                        data=output_text,
                        file_name=f"Ù…Ù„Ø§Ø­Ø¸Ø§Øª_Ù…Ø±ØªØ¨Ø©_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                        mime="text/plain"
                    )
                
                with col_result3:
                    if st.button("ğŸ”„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰"):
                        st.rerun()
    else:
        st.error(f"âŒ {error_msg}")

# Ø¹Ø±Ø¶ Ø§Ù„ØªØ§Ø±ÙŠØ®

if â€˜historyâ€™ in st.session_state and st.session_state.history:
st.markdown(â€â€”â€)
st.subheader(â€œğŸ“š ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øªâ€)
# Ø®ÙŠØ§Ø± Ù„Ø¥Ø¸Ù‡Ø§Ø±/Ø¥Ø®ÙØ§Ø¡ Ø§Ù„ØªØ§Ø±ÙŠØ®
show_history = st.checkbox("Ø¥Ø¸Ù‡Ø§Ø± Ø§Ù„ØªØ§Ø±ÙŠØ®")

if show_history:
    for i, item in enumerate(reversed(st.session_state.history[-5:])):  # Ø¢Ø®Ø± 5 Ø¹Ù†Ø§ØµØ±
        with st.expander(f"ğŸ“ {item['timestamp']} - {item['style']}"):
            st.markdown("**Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ:**")
            st.text(item['original'][:200] + "..." if len(item['original']) > 200 else item['original'])
            st.markdown("**Ø§Ù„Ù†ØªÙŠØ¬Ø©:**")
            st.markdown(item['processed'])
            st.caption(f"Ø§Ù„Ù…Ù‚Ø¯Ù…: {item['provider']}")

# ØªØ°ÙŠÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚

st.markdown(â€â€”â€)
st.markdown(
â€œâ€â€
<div style="text-align: center; color: #7F8C8D;">
ğŸš€ ØªÙ… ØªØ·ÙˆÙŠØ± Ø§Ù„Ù†ÙˆØª Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…Ø­Ø³Ù† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Streamlit<br>
ğŸ’¡ ÙŠØ¯Ø¹Ù… Ù…ØªØ¹Ø¯Ø¯ Ù…Ù‚Ø¯Ù…ÙŠ Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
</div>
â€œâ€â€,
unsafe_allow_html=True
)
